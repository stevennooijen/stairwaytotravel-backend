{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Wikivoyage\n",
    "\n",
    "Assumes wikivoyage data has been parsed into a dataframe with metadata and a generator for creating the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../data/wikivoyage/processed/'\n",
    "api_dir = '../../../api/data/'\n",
    "\n",
    "path_wiki_metadata_in  = data_dir + 'wikivoyage_metadata_all.csv'\n",
    "path_wiki_metadata_out = data_dir + 'wikivoyage_destinations.csv'\n",
    "path_api_out = api_dir + 'wikivoyage_destinations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for base product\n",
    "\n",
    "Essentials (= scope of this notebook):\n",
    "- Structured metadata:\n",
    "    * Destination name\n",
    "    * Geolocation\n",
    "    * Parent, needed for retrieving country (but could also be done on geolocation?)\n",
    "- Unstructured content:\n",
    "    * Embeddings for retrieving activities\n",
    "\n",
    "Also retrieved in the past, but not yet needed (= not in scope):\n",
    "- Redirect names so that people can search by name?\n",
    "- Links to other datasets: DMOZ, Commons, Wikipedia\n",
    "- Full hierarchy\n",
    "- Number of direct children & sum of all children destinations\n",
    "- Number of parents, and whether the parent is 'odd' (parent is park or city)\n",
    "- Continent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    # converter is not needed if converted earlier at extraction\n",
    "    pd.read_csv(path_wiki_metadata_in, converters={'status' : str.lower})\n",
    "    # throw away one odd case in which the title is missing\n",
    "    .loc[lambda df: ~df['title'].isnull()]\n",
    ")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Setting some of the parents manually\n",
    "\n",
    "Note: \"World\" for the continents is later undone, as \"World\" redirects to \"Destinations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set is part of for continents\n",
    "data.loc[(data['ispartof'].isnull()) & (data['articletype'] == 'continent'), 'ispartof'] = 'World'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some destinations have a missign parent that cannot be fixed programatically:\n",
    "* \"Sonoma County\" doesn't have any parent listed in it's xml text...\n",
    "\n",
    "So, for these let's also set `ispartof` manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[lambda df: df['title'] == 'Sonoma County', 'ispartof'] = 'North Coast (California)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope data: throw away most irrelevant content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    data.copy()  \n",
    "    .loc[lambda df: ~df['title'].isin(['Space', 'Moon'])]  # these are of type 'park' so need to excl. them by name\n",
    "    .loc[lambda df: ~df['title'].str.contains('disambiguation')]\n",
    "    .loc[lambda df: df['disambiguation'] == False]\n",
    "    .loc[lambda df: df['historical'] == False]\n",
    "    .loc[lambda df: ~df['articletype'].isnull()]\n",
    "    .loc[lambda df: ~df['ispartof'].isnull()]\n",
    ")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the parent path for each destination\n",
    "\n",
    "Before we can get each parent, we need to replace all `title`'s and `ispartof`'s with their redirects if available. This way we can avoid 'broken chains' wheren an `ispartof` refers to a redirect title instead of a title.\n",
    "\n",
    "To do this we create a lookup dataframe and apply a function to replace the title if there is a redirect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_title_with_redirect_if_possible(title, lookup_df):\n",
    "    redirect_title = lookup_df.loc[lookup_df['title'] == title, 'redirect']\n",
    "    return redirect_title.iat[0] if len(redirect_title) > 0 else title\n",
    "\n",
    "redirect_table = (\n",
    "    data\n",
    "    .loc[lambda df: ~df['redirect'].isnull()]\n",
    "    [['pageid', 'title', 'redirect']]\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# filter away all redirects\n",
    "df = df.loc[lambda df: df['redirect'].isnull()]\n",
    "\n",
    "df['title'] = df.apply(lambda x: replace_title_with_redirect_if_possible(x['title'], redirect_table), axis=1)\n",
    "df['ispartof'] = df.apply(lambda x: replace_title_with_redirect_if_possible(x['ispartof'], redirect_table), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do a left join with itself to get the `parentid`. We need lowercased helper columns for the join as sometimes the capitals between the `title` and `ispartof` don't match. For example \"Geraldton (Ontario)\" has as a parent \"northern Ontario\" versus the actual record that starts with a capital N: \"Northern Ontario\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case_matching_df = (\n",
    "    df[['pageid', 'title']]\n",
    "    # lowercase for better matching\n",
    "    .assign(title_lower = lambda df: df['title'].str.lower())\n",
    "    .drop('title', axis=1)\n",
    "    # rename columns for matching\n",
    "    .rename({'pageid' : 'parentid'}, axis=1)\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .assign(ispartof_lower = lambda df: df['ispartof'].str.lower())\n",
    "    .merge(lower_case_matching_df, how='left', left_on='ispartof_lower', right_on='title_lower')\n",
    "    .drop(['title_lower', 'ispartof_lower'], axis=1)\n",
    "#     .assign(parentid = lambda df: df['parentid'].astype(int))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `parentid` for \"Destinations\" and \"Other destinations\" to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ispartof'] == 'Destinations', 'parentid'] = 0\n",
    "df.loc[df['ispartof'] == 'Other destinations', 'parentid'] = 0\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope data: require good articletype and having a parent\n",
    "\n",
    "Focus on core destinations content here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_scoped = (\n",
    "    df.copy()  \n",
    "    .loc[lambda df: df['articletype'].isin(['district', 'city', 'region', 'park', 'country', 'continent'])]\n",
    ")\n",
    "print(df_scoped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check uitval o.b.v. parent matching. Zo weinig op dit punt. Gewoon negeren/deleten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uitval_parent = (\n",
    "    df_scoped\n",
    "    .copy()\n",
    "    .loc[lambda df: df['parentid'].isnull()]\n",
    "#     .loc[lambda df: ~df['ispartof'].isin(['Destinations', 'Other destinations'])]\n",
    ")\n",
    "print(uitval_parent.shape)\n",
    "uitval_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scoped = (\n",
    "    df_scoped.loc[lambda df: ~df['parentid'].isnull()]\n",
    "    # finally convert parent_id into int now that it's always available\n",
    "    .assign(parentid = lambda df: df['parentid'].astype(int))\n",
    ")\n",
    "print(df_scoped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save country as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_record(pageid, lookup_df):\n",
    "    return lookup_df.loc[lookup_df['pageid'] == pageid].iloc[0]\n",
    "\n",
    "def find_parent(pageid, lookup_df):\n",
    "    current_record = find_record(pageid, lookup_df)\n",
    "    articletype, country, parentid = current_record['articletype'], current_record['title'], current_record['parentid']\n",
    "    \n",
    "    # loop until country found, or no other possibilities left\n",
    "    while (current_record['articletype'] != 'country') and (current_record['parentid'] != 0):\n",
    "        \n",
    "        # lookup parent record and get type\n",
    "        current_record = find_record(current_record['parentid'], lookup_df)\n",
    "        articletype, country, parentid = current_record['articletype'], current_record['title'], current_record['parentid']\n",
    "                \n",
    "#     when done with loop, return country name if found\n",
    "    return country if articletype == 'country' else None\n",
    "\n",
    "\n",
    "lookup_df = df_scoped.copy()\n",
    "df_scoped['country'] = df_scoped['pageid'].apply(lambda x: find_parent(x, lookup_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite some destinations for which a country couldn't been found. Many of these are special regions, belonging to bigger countries, like many of the carribean islands:\n",
    "\n",
    "- Puerto Rico\n",
    "- Cayman Islands\n",
    "- U.S. Virgin Islands\n",
    "- Bonaire\n",
    "- French Guiana (doesn't have its own flag, but is part of France - could set France as parentid)\n",
    "\n",
    "However, many of these islands have their own flag. Need to solve that by matching with some flag dataset in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uitval_country = df_scoped.loc[(df_scoped['country'].isnull()) & (df_scoped['articletype'] != \"region\")].copy()\n",
    "print(uitval_country.shape)\n",
    "uitval_country.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure any destination has a country feature value, set it to `ispartof` when `country` is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scoped.loc[lambda df: df['country'].isnull(), 'country'] = df_scoped.loc[lambda df: df['country'].isnull(), 'ispartof']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope data: select only end destinations\n",
    "\n",
    "Keep cities and parks only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dest = (\n",
    "    df_scoped\n",
    "    .loc[lambda df: df['articletype'].isin(['city', 'park'])]\n",
    "    .drop(['redirect', 'disambiguation', 'historical'], axis=1)\n",
    ")\n",
    "print(df_dest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope data: require geo location\n",
    "\n",
    "Make sure all have a geo location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uitval_geo = df_dest.loc[lambda df: (df['lat'].isnull()) | (df['lon'].isnull())].copy()\n",
    "\n",
    "print(uitval_geo.shape)\n",
    "uitval_geo.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_dest.loc[lambda df: (~df['lat'].isnull()) & (~df['lon'].isnull())].copy()\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: make sure input dataframe longitude columns is renamed from `lon` to `lng`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_final\n",
    "    .rename(columns={'pageid': 'id', 'title': 'name', 'articletype': 'type', 'lon': 'lng'})\n",
    "    .to_csv(path_api_out, index=False)\n",
    "#     .to_csv(path_wiki_metadata_out, index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
