{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create instagram post list\n",
    "\n",
    "This notebook creates a csv with information on X amount of Flickr images per places in our database. It does so using scripts for the following 3 steps:\n",
    "\n",
    "1. For each destination, query the top X most interesting images from Flickr. \n",
    "2. For each author found, query people info to know more about the author.\n",
    "3. For each place, query the wikivoyage place url for a quick link to more info.\n",
    "\n",
    "All (intermediate) query results are saved so that we don't need to query again.\n",
    "\n",
    "In this first run, we query the top 20 images per place. We better have the data, and then we can always do the image generation only for the top 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/'\n",
    "\n",
    "TOP_X_IMAGES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from stairway.apis.flickr.people import get_flickr_people_info, parse_flickr_people_info\n",
    "from stairway.apis.wikivoyage.page_info import get_wikivoyage_page_info\n",
    "from stairway.instagram.description import pick_generic_hastags, clean_text, create_draft_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read place data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# places_file = data_dir + 'wikivoyage/enriched/wikivoyage_destinations.csv'\n",
    "\n",
    "# df = (\n",
    "#     pd.read_csv(places_file)\n",
    "#     .rename(columns={'id': 'stairway_id'})\n",
    "#     .set_index(\"stairway_id\", drop=False)\n",
    "#     [['stairway_id', 'name', 'country', 'nr_tokens', 'wiki_id']]\n",
    "# )\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Query the api and explode the DF\n",
    "\n",
    "Implementation moved to `scripts/flickr_image_list.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = pd.read_csv(data_dir + 'flickr/flickr_image_list.csv')\n",
    "df_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Flickr people info\n",
    "\n",
    "Use https://www.flickr.com/services/api/flickr.people.getInfo.html\n",
    "\n",
    "First deduplicate the authors from the image list, then retrieve info and join back to avoid querying a single author multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user = '12962905@N05'  #kevinpoh\n",
    "# user = '61713368@N07'  #tiket2\n",
    "# user = '143466180@N07'  # removed user\n",
    "\n",
    "# output = get_flickr_people_info(user, api_key=FLICKR_KEY)\n",
    "# output = parse_flickr_people_info(output)\n",
    "\n",
    "# output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation moved to `scripts/flickr_people_list.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = pd.read_csv(data_dir + \"flickr/flickr_people_list.csv\").drop_duplicates()\n",
    "df_people.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add link to wiki travel for ease of use\n",
    "\n",
    "Use `wiki_id` and query up to 50 wiki_ids at the same time.\n",
    "\n",
    "Implementation moved to `scripts/wikivoyage_page_info.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = get_wikivoyage_page_info([10, 33, 36])\n",
    "\n",
    "# [v['fullurl'] for k, v in data.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki_info = pd.read_csv(data_dir + \"wikivoyage/clean/wikivoyage_page_info.csv\").drop_duplicates()\n",
    "df_wiki_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join all tables together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join the people table with the image table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = (\n",
    "    df_images\n",
    "    .merge(df_people, left_on='owner', right_on=\"nsid\")\n",
    ")\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join the wiki links with the image table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = (\n",
    "    df_all\n",
    "    # there is a conflicting 'title' in the image dataset\n",
    "    .merge(df_wiki_info.drop(columns=['title']), left_on='wiki_id', right_on='pageid')\n",
    ")\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add a draft description to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['draft_text'] = df_all.apply(lambda df: create_draft_description(df['name'], df['country'], df['path_alias']), axis=1)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump the final list to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step, is making a nice subselection of the variables and putting them in de right order for the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename = {'index': 'image_nr',\n",
    "                 'title': 'image_title', \n",
    "                 'path_alias': 'owner_tag', \n",
    "                 'location': 'owner_location', \n",
    "                 'fullurl': 'wiki_url'}\n",
    "column_order = ['stairway_id', 'index', 'name', 'country', 'article_length', 'title', 'ownername', \n",
    "                'realname', 'path_alias', 'location', 'profileurl', 'image_url', 'fullurl', 'draft_text']\n",
    "\n",
    "df_insta = (\n",
    "    df_all        \n",
    "    .assign(article_length = lambda df: df['length'].astype(int))\n",
    "    .loc[lambda df: df['index'] < TOP_X_IMAGES]\n",
    "    [column_order]\n",
    "    .rename(columns=column_rename)\n",
    ")\n",
    "df_insta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insta.to_csv(data_dir + 'instagram/instagram_post_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps: \n",
    "1. Import the CSV into Google Spreadsheets\n",
    "2. Process the images in this list and upload them in Google Drive.\n",
    "\n",
    "Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
