{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat instagram post list\n",
    "\n",
    "This notebook creates a csv with information on X amount of Flickr images per places in our database. It does so in 3 steps:\n",
    "\n",
    "1. For each destination, query the top X most interesting images from Flickr. \n",
    "2. For each author found, query people info to know more about the author.\n",
    "3. For each place, query the wikivoyage place url for a quick link to more info.\n",
    "\n",
    "All (intermediate) query results are saved so that we don't need to query again.\n",
    "\n",
    "In this first run, we query the top 20 images per place. We better have the data, and then we can always do the image generation only for the top 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_X_IMAGES = 20\n",
    "\n",
    "output_dir = '../../data/flickr/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from stairway.apis.flickr.photos import get_flickr_images, create_image_url, create_attribution_url\n",
    "from stairway.apis.flickr.people import get_flickr_people_info, parse_flickr_people_info\n",
    "from stairway.apis.wikivoyage.page import get_wikivoyage_page_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLICKR_KEY = os.getenv('FLICKR_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/wikivoyage/enriched/'\n",
    "\n",
    "file_name = 'wikivoyage_destinations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.read_csv(data_dir + file_name)\n",
    "    .rename(columns={'id': 'stairway_id'})\n",
    "    .set_index(\"stairway_id\", drop=False)\n",
    "    [['stairway_id', 'name', 'country', 'nr_tokens', 'wiki_id']]\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Query the api and explode the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flickr_images(df, nr_images=TOP_X_IMAGES):\n",
    "    \"Takes a df of a single row and explodes it into the nr of entries found\"\n",
    "    flickr_json = get_flickr_images(df[\"search_string\"].iloc[0], \n",
    "                                    api_key=FLICKR_KEY, \n",
    "                                    images_per_page=nr_images)['photo']\n",
    "\n",
    "    if len(flickr_json) > 0: \n",
    "        flickr_df = (\n",
    "            pd.DataFrame(flickr_json)\n",
    "            .assign(url_b = lambda df: create_image_url(df))\n",
    "            .assign(image_url = lambda df: create_attribution_url(df))\n",
    "    #         [['id', 'owner', 'title', 'image_url', 'ownername', 'url_b', 'url_o', 'height_o', 'width_o']]\n",
    "        )\n",
    "\n",
    "        repeated_df = (\n",
    "            pd.concat([df]*len(flickr_json), ignore_index=True)\n",
    "            .reset_index()\n",
    "            [['stairway_id', 'index', 'name', 'country', 'nr_tokens', 'wiki_id']]\n",
    "        )\n",
    "        \n",
    "        df_out = pd.concat([repeated_df, flickr_df], axis=1)\n",
    "    else: \n",
    "        df_out = None\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = (\n",
    "    df\n",
    "    .reset_index(drop=True)\n",
    "    .assign(search_string = lambda df: df['name'] + ' ' + df['country'])\n",
    "    .groupby('stairway_id')\n",
    "    .apply(find_flickr_images)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images.to_csv(output_dir + 'flickr_top5_images_per_place.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Flickr people info\n",
    "\n",
    "Use https://www.flickr.com/services/api/flickr.people.getInfo.html\n",
    "\n",
    "First deduplicate the authors from the image list, then retrieve info and join back to avoid querying a single author multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user = '12962905@N05'  #kevinpoh\n",
    "# user = '61713368@N07'  #tiket2\n",
    "\n",
    "# output = get_flickr_people_info(user, api_key=FLICKR_KEY)\n",
    "# output = parse_flickr_people_info(output)\n",
    "\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = pd.DataFrame(\n",
    "    [parse_flickr_people_info(get_flickr_people_info(author, api_key=FLICKR_KEY))\n",
    "     for author in \n",
    "#      df_images['owner'].unique()\n",
    "     df_images['owner'].drop_duplicates()\n",
    "    ])\n",
    "\n",
    "\n",
    "df_people = df_images[['owner']].drop_duplicates(ignore_index=True).join(df_people) \n",
    "\n",
    "df_people.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people.to_csv(output_dir + 'flickr_top5_images_per_place_owners.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join the people table with the image table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = (\n",
    "    df_images\n",
    "    .merge(df_people, on='owner')\n",
    ")\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add link to wiki travel for ease of use\n",
    "\n",
    "Use `wiki_id` of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = get_wikivoyage_page_info(33)\n",
    "\n",
    "# data['fullurl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikivoyage_fullurl(wiki_id):\n",
    "    data = get_wikivoyage_page_info(wiki_id)\n",
    "    return data['fullurl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikiurls = df['wiki_id'].apply(get_wikivoyage_fullurl).to_frame(name='wiki_url').reset_index()\n",
    "\n",
    "df_wikiurls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikiurls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikiurls.to_csv(output_dir + 'wikivoyage_place_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join the wiki links with the image table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = (\n",
    "    df_all\n",
    "    .merge(df_wikiurls, on='stairway_id')\n",
    ")\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump the final list to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(output_dir + 'instagram_post_list_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step, is making a nice subselection of the variables and putting them in de right order for the overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['stairway_id', 'index', 'name', 'country', 'nr_tokens', 'title', 'ownername', \n",
    "                'realname', 'path_alias', 'location', 'profileurl', 'image_url', 'wiki_url']\n",
    "column_rename = {'title': 'image_title', 'path_alias': 'owner_tag', 'location': 'owner_location'}\n",
    "\n",
    "(\n",
    "    df_all\n",
    "    .loc[lambda df: df['index'] < 5]\n",
    "    [column_order]\n",
    "    .rename(columns=column_rename)\n",
    "    .to_csv(output_dir + 'instagram_post_list.csv', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
